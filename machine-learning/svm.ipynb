{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "Support vector machine（支持向量机）,是一种分类算法，它的特点在于找出的分类面是最优的。对于二维数据来说，它可以找到一条直线，这是无数条可以分类的直线当中最完美的，因为它恰好在两个类的中间，距离两个类的点都一样远。如果是高维的点，SVM的分界线就是平面或者超平面（hyperplane）。其算法效果可由下图所示：\n",
    "\n",
    "![svm1](./resources/svm1.jpg)\n",
    "\n",
    "上图中，Boundary代表决策面，Margin代表分类间隔，Support Vector代表离决策面最近的那些数据点（虚线穿过的点）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是：如果一个类别的数据点跑到了另一类别中，那么它就是该类别的离散值。SVM 的一个特征就是会忽略离散值并找到具有最大边距的超平面。因此，我们可以说，SVM 对于离散值具有鲁棒性。\n",
    "\n",
    "SVM有核函数，该函数具有将低维数据转化成高维数据的作用，它可将不可分离的问题转换成可分离的问题。\n",
    "\n",
    "**实际上最优决策面的方向和位置完全取决于选择哪些样本点作为支持向量**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 求解最优决策面\n",
    "\n",
    "一个最优化问题通常有两个最基本的因素：\n",
    "- 目标函数，也就是你希望什么东西的什么指标达到最好;\n",
    "- 优化对象，你期望通过改变哪些因素来使你的目标函数达到最优;\n",
    "\n",
    "在线性SVM算法中，目标函数是**分类间隔**，而优化对象则是**决策面**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Representation\n",
    "\n",
    "求解最优决策面最直接的表达形式如下所示，其中$margin$函数可以输入一个$boundary$，计算正确分类的所有苹果与香蕉到$boundary$的最小距离。\n",
    "\n",
    "> $argmax_{boundary} \\ margin(boundary)$  \n",
    "> $s.t.$ 所有正确归类的苹果与香蕉到$boundary$的距离都$>=margin$\n",
    "\n",
    "考虑使用数学表达来描述：\n",
    "\n",
    "1.定义直线$x_2=ax_1+b$为决策面，经过变换可以得到：$\\boldsymbol{\\omega}^T\\boldsymbol{x}+\\gamma=0$，需要注意$\\omega$控制了直线的方向。\n",
    "\n",
    "2.平面上任意点$x_0$到直线的距离为：$\\dfrac{1}{||\\boldsymbol{\\omega}||}(\\boldsymbol{\\omega}^Tx_0+\\gamma)$；假设支持向量到决策面的距离为$d$，则所有样本点需要满足：$\\left\\{\\begin{array}{ll} (\\boldsymbol{\\omega}^T\\boldsymbol{x}_i+\\gamma)/||\\boldsymbol{\\omega}||\\geq d & \\forall~ y_i=1\\\\(\\boldsymbol{\\omega}^T\\boldsymbol{x}_i+\\gamma)/||\\boldsymbol{\\omega}||\\leq -d & \\forall~y_i=-1\\end{array}\\right. $\n",
    "，两边同除以$d$不影响原决策面的方向与截距，则SVM优化的约束条件变为：$\\left\\{\\begin{array}{ll} \\boldsymbol{\\omega}^T\\boldsymbol{x}_i+\\gamma\\geq 1 & \\textrm{for} \\  y_i=1\\\\\\boldsymbol{\\omega}^T\\boldsymbol{x}_i+\\gamma\\leq -1 & \\textrm{for} \\ y_i=-1\\end{array}\\right. $。\n",
    "需要注意的是：支持向量样本点到决策面方程的距离就是$1/||\\boldsymbol{\\omega}||$（等于1或者-1只发生在样本点为支持向量的时候），则问题转化为求$||\\boldsymbol{\\omega}||$最小值的问题。综上，SVM最优化问题的数学描述为：\n",
    "\n",
    "> $\\begin{array}{l} \\min_{\\boldsymbol{\\omega},\\gamma}\\frac{1}{2}||\\boldsymbol{\\omega}||^2\\\\ \\textrm{s. t.}~ ~y_i(\\boldsymbol{\\omega}^T\\boldsymbol{x}_i+\\gamma)\\geq 1,~~i = 1,2,...,m \\end{array}$\n",
    "\n",
    "缩写s.t.表示“Subject to”，是“服从某某条件”的意思，之所以要在$||\\boldsymbol{\\omega}||$上加上平方和1/2的系数，是为了以后进行最优化的过程中对目标函数求导时比较方便,但这绝不影响最优化问题最后的解。于是，求解SVM最优决策面的问题转化成了一个**不等式约束条件下的优化问题**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
