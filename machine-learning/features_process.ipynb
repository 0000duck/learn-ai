{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Process\n",
    "\n",
    "## 特征缩放\n",
    "在我们面对多维特征问题的时候，我们要保证这些特征都具有相近的尺度，这将帮助梯度下降算法更快地收敛。简单的方法：  \n",
    "$x_n=\\dfrac{x_n-u_n}{s_n}$  \n",
    "其中$u_n$式平均值，$s_n$是标准差。\n",
    "\n",
    "## 正则化(Regularization)\n",
    "- 过拟合：过于强调拟合原始数据（如用高次多项式模型）；\n",
    "- 欠拟合：不能很好的适应训练集（如用线性模型）；\n",
    "\n",
    "处理过拟合：(1) 丢弃一些特征；(2) 正则化(保留所有的特征，但是减少参数的大小)；\n",
    "\n",
    "正则化思想：正是那些高次项导致了过拟合的产生，所以如果我们能让这些高次项的系数接近于0的话，我们就能很好的拟合了。 所以我们要做的就是在一定程度上减小这些参数的值，这就是正则化的基本方法。\n",
    "\n",
    "对于高次多项式模型：$h_\\theta(x)=\\theta_0+\\theta_1x_1+\\theta_2x_2^2+\\theta_3x_3^3$，我们决定减少$\\theta_3$与$\\theta_4$的大小，方法就是**修改代价函数**，在这两个参数上设置一点惩罚。修改后的代价函数改为：  \n",
    "\n",
    "$J(\\theta) = \\dfrac{1}{2m}[\\sum_{i=1}^m (h_{\\theta}(x^{(i)})-y^{(i)} )^{2} + 1000\\theta_3^2 + 10000\\theta_4^2]$\n",
    "\n",
    "假如我们有非常多的特征，我们并不知道其中哪些特征我们要惩罚，我们将对所有的特征进行惩罚，并且让代价函数最优化的软件来选择这些惩罚的程度。（它的核心在于：**都在原有算法更新规则的基础上令值$\\theta$减少一个额外的值**)\n",
    "\n",
    "$J(\\theta) = \\dfrac{1}{2m}[\\sum_{i=1}^m (h_{\\theta}(x^{(i)})-y^{(i)} )^{2} + \\lambda\\sum_{j=1}^n\\theta_j^2]$\n",
    "\n",
    "> 需要合理的调控正则化参数$\\lambda$的值：它太大，会欠拟合；它太小，会过拟合  \n",
    "> 我们不惩罚$\\theta_0$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
